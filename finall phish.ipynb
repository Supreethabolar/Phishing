{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "f1b81290",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting fea.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile fea.py\n",
    "\"\"\"\n",
    "from bs4 import BeautifulSoup\n",
    "with open(\"mini_dataset/6.html\") as f:\n",
    "    test = f.read()\n",
    "soup = BeautifulSoup(test, \"html.parser\")\n",
    "\"\"\"\n",
    "\n",
    "\n",
    "# has_title\n",
    "def has_title(soup):\n",
    "    if soup.title is None:\n",
    "        return 0\n",
    "    if len(soup.title.text) > 0:\n",
    "        return 1\n",
    "    else:\n",
    "        return 0\n",
    "\n",
    "\n",
    "# has_input\n",
    "def has_input(soup):\n",
    "    if len(soup.find_all(\"input\")):\n",
    "        return 1\n",
    "    else:\n",
    "        return 0\n",
    "\n",
    "\n",
    "# has_button\n",
    "def has_button(soup):\n",
    "    if len(soup.find_all(\"button\")) > 0:\n",
    "        return 1\n",
    "    else:\n",
    "        return 0\n",
    "\n",
    "\n",
    "# has_image\n",
    "def has_image(soup):\n",
    "    if len(soup.find_all(\"image\")) == 0:\n",
    "        return 0\n",
    "    else:\n",
    "        return 1\n",
    "\n",
    "\n",
    "# has_submit\n",
    "def has_submit(soup):\n",
    "    for button in soup.find_all(\"input\"):\n",
    "        if button.get(\"type\") == \"submit\":\n",
    "            return 1\n",
    "        else:\n",
    "            pass\n",
    "    return 0\n",
    "\n",
    "\n",
    "# has_link\n",
    "def has_link(soup):\n",
    "    if len(soup.find_all(\"link\")) > 0:\n",
    "        return 1\n",
    "    else:\n",
    "        return 0\n",
    "\n",
    "\n",
    "# has_password\n",
    "def has_password(soup):\n",
    "    for input in soup.find_all(\"input\"):\n",
    "        if (input.get(\"type\") or input.get(\"name\") or input.get(\"id\")) == \"password\":\n",
    "            return 1\n",
    "        else:\n",
    "            pass\n",
    "    return 0\n",
    "\n",
    "\n",
    "# has_email_input\n",
    "def has_email_input(soup):\n",
    "    for input in soup.find_all(\"input\"):\n",
    "        if (input.get(\"type\") or input.get(\"id\") or input.get(\"name\")) == \"email\":\n",
    "            return 1\n",
    "        else:\n",
    "            pass\n",
    "    return 0\n",
    "\n",
    "\n",
    "# has_hidden_element\n",
    "def has_hidden_element(soup):\n",
    "    for input in soup.find_all(\"input\"):\n",
    "        if input.get(\"type\") == \"hidden\":\n",
    "            return 1\n",
    "        else:\n",
    "            pass\n",
    "    return 0\n",
    "\n",
    "\n",
    "# has_audio\n",
    "def has_audio(soup):\n",
    "    if len(soup.find_all(\"audio\")) > 0:\n",
    "        return 1\n",
    "    else:\n",
    "        return 0\n",
    "\n",
    "\n",
    "# has_video\n",
    "def has_video(soup):\n",
    "    if len(soup.find_all(\"video\")) > 0:\n",
    "        return 1\n",
    "    else:\n",
    "        return 0\n",
    "\n",
    "\n",
    "# number_of_inputs\n",
    "def number_of_inputs(soup):\n",
    "    return len(soup.find_all(\"input\"))\n",
    "\n",
    "\n",
    "# number_of_buttons\n",
    "def number_of_buttons(soup):\n",
    "    return len(soup.find_all(\"button\"))\n",
    "\n",
    "\n",
    "# number_of_images\n",
    "def number_of_images(soup):\n",
    "    image_tags = len(soup.find_all(\"image\"))\n",
    "    count = 0\n",
    "    for meta in soup.find_all(\"meta\"):\n",
    "        if meta.get(\"type\") or meta.get(\"name\") == \"image\":\n",
    "            count += 1\n",
    "    return image_tags + count\n",
    "\n",
    "\n",
    "# number_of_option\n",
    "def number_of_option(soup):\n",
    "    return len(soup.find_all(\"option\"))\n",
    "\n",
    "\n",
    "# number_of_list\n",
    "def number_of_list(soup):\n",
    "    return len(soup.find_all(\"li\"))\n",
    "\n",
    "\n",
    "# number_of_TH\n",
    "def number_of_TH(soup):\n",
    "    return len(soup.find_all(\"th\"))\n",
    "\n",
    "\n",
    "# number_of_TR\n",
    "def number_of_TR(soup):\n",
    "    return len(soup.find_all(\"tr\"))\n",
    "\n",
    "\n",
    "# number_of_href\n",
    "def number_of_href(soup):\n",
    "    count = 0\n",
    "    for link in soup.find_all(\"link\"):\n",
    "        if link.get(\"href\"):\n",
    "            count += 1\n",
    "    return count\n",
    "\n",
    "\n",
    "# number_of_paragraph\n",
    "def number_of_paragraph(soup):\n",
    "    return len(soup.find_all(\"p\"))\n",
    "\n",
    "\n",
    "# number_of_script\n",
    "def number_of_script(soup):\n",
    "    return len(soup.find_all(\"script\"))\n",
    "\n",
    "\n",
    "# length_of_title\n",
    "def length_of_title(soup):\n",
    "    if soup.title == None:\n",
    "        return 0\n",
    "    return len(soup.title.text)\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "print(\"has_title --> \", has_title(soup))\n",
    "print(\"has_input --> \", has_input(soup))\n",
    "print(\"has_button --> \", has_button(soup))\n",
    "print(\"has_image --> \", has_image(soup))\n",
    "print(\"has_submit --> \", has_submit(soup))\n",
    "print(\"has_link --> \", has_link(soup))\n",
    "print(\"has_password --> \", has_password(soup))\n",
    "print(\"has_email_input --> \", has_email_input(soup))\n",
    "print(\"has_hidden_element --> \", has_hidden_element(soup))\n",
    "print(\"has_audio --> \", has_audio(soup))\n",
    "print(\"has_video --> \", has_video(soup))\n",
    "print(\"number_of_inputs --> \", number_of_inputs(soup))\n",
    "print(\"number_of_buttons --> \", number_of_buttons(soup))\n",
    "print(\"number_of_images --> \", number_of_images(soup))\n",
    "print(\"number_of_option --> \", number_of_option(soup))\n",
    "print(\"number_of_list --> \", number_of_list(soup))\n",
    "print(\"number_of_TH --> \", number_of_TH(soup))\n",
    "print(\"number_of_TR --> \", number_of_TR(soup))\n",
    "print(\"number_of_href --> \", number_of_href(soup))\n",
    "print(\"number_of_paragraph --> \", number_of_paragraph(soup))\n",
    "print(\"number_of_script --> \", number_of_script(soup))\n",
    "print(\"length_of_title --> \", length_of_title(soup))\n",
    "\"\"\"\n",
    "\n",
    "\n",
    "# has h1\n",
    "def has_h1(soup):\n",
    "    if len(soup.find_all(\"h1\")) > 0:\n",
    "        return 1\n",
    "    else:\n",
    "        return 0\n",
    "\n",
    "\n",
    "# has h2\n",
    "def has_h2(soup):\n",
    "    if len(soup.find_all(\"h2\")) > 0:\n",
    "        return 1\n",
    "    else:\n",
    "        return 0\n",
    "\n",
    "\n",
    "# has h3\n",
    "def has_h3(soup):\n",
    "    if len(soup.find_all(\"h3\")) > 0:\n",
    "        return 1\n",
    "    else:\n",
    "        return 0\n",
    "\n",
    "\n",
    "# length of text\n",
    "def length_of_text(soup):\n",
    "    return len(soup.get_text())\n",
    "\n",
    "\n",
    "# number of clickable button\n",
    "def number_of_clickable_button(soup):\n",
    "    count = 0\n",
    "    for button in soup.find_all(\"button\"):\n",
    "        if button.get(\"type\") == \"button\":\n",
    "            count += 1\n",
    "    return count\n",
    "\n",
    "\n",
    "# number of a\n",
    "def number_of_a(soup):\n",
    "    return len(soup.find_all(\"a\"))\n",
    "\n",
    "\n",
    "# number of img\n",
    "def number_of_img(soup):\n",
    "    return len(soup.find_all(\"img\"))\n",
    "\n",
    "\n",
    "# number of div class\n",
    "def number_of_div(soup):\n",
    "    return len(soup.find_all(\"div\"))\n",
    "\n",
    "\n",
    "# number of figures\n",
    "def number_of_figure(soup):\n",
    "    return len(soup.find_all(\"figure\"))\n",
    "\n",
    "\n",
    "# has footer\n",
    "def has_footer(soup):\n",
    "    if len(soup.find_all(\"footer\")) > 0:\n",
    "        return 1\n",
    "    else:\n",
    "        return 0\n",
    "\n",
    "\n",
    "# has form\n",
    "def has_form(soup):\n",
    "    if len(soup.find_all(\"form\")) > 0:\n",
    "        return 1\n",
    "    else:\n",
    "        return 0\n",
    "\n",
    "\n",
    "# has textarea\n",
    "def has_text_area(soup):\n",
    "    if len(soup.find_all(\"textarea\")) > 0:\n",
    "        return 1\n",
    "    else:\n",
    "        return 0\n",
    "\n",
    "\n",
    "# has iframe\n",
    "def has_iframe(soup):\n",
    "    if len(soup.find_all(\"iframe\")) > 0:\n",
    "        return 1\n",
    "    else:\n",
    "        return 0\n",
    "\n",
    "\n",
    "# has text input\n",
    "def has_text_input(soup):\n",
    "    for input in soup.find_all(\"input\"):\n",
    "        if input.get(\"type\") == \"text\":\n",
    "            return 1\n",
    "    return 0\n",
    "\n",
    "\n",
    "# number of meta\n",
    "def number_of_meta(soup):\n",
    "    return len(soup.find_all(\"meta\"))\n",
    "\n",
    "\n",
    "# has nav\n",
    "def has_nav(soup):\n",
    "    if len(soup.find_all(\"nav\")) > 0:\n",
    "        return 1\n",
    "    else:\n",
    "        return 0\n",
    "\n",
    "\n",
    "# has object\n",
    "def has_object(soup):\n",
    "    if len(soup.find_all(\"object\")) > 0:\n",
    "        return 1\n",
    "    else:\n",
    "        return 0\n",
    "\n",
    "\n",
    "# has picture\n",
    "def has_picture(soup):\n",
    "    if len(soup.find_all(\"picture\")) > 0:\n",
    "        return 1\n",
    "    else:\n",
    "        return 0\n",
    "\n",
    "\n",
    "# number of sources\n",
    "def number_of_sources(soup):\n",
    "    return len(soup.find_all(\"source\"))\n",
    "\n",
    "\n",
    "# number of span\n",
    "def number_of_span(soup):\n",
    "    return len(soup.find_all(\"span\"))\n",
    "\n",
    "\n",
    "# number of table\n",
    "def number_of_table(soup):\n",
    "    return len(soup.find_all(\"table\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0875625e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"\\n# 5 CREATE A DATAFRAME BY USING 2-D ARRAY\\ndata = create_2d_list(folder)\\ncolumns = [\\n    'has_title',\\n    'has_input',\\n    'has_button',\\n    'has_image',\\n    'has_submit',\\n    'has_link',\\n    'has_password',\\n    'has_email_input',\\n    'has_hidden_element',\\n    'has_audio',\\n    'has_video',\\n    'number_of_inputs',\\n    'number_of_buttons',\\n    'number_of_images',\\n    'number_of_option',\\n    'number_of_list',\\n    'number_of_th',\\n    'number_of_tr',\\n    'number_of_href',\\n    'number_of_paragraph',\\n    'number_of_script',\\n    'length_of_title',\\n    'has_h1',\\n    'has_h2',\\n    'has_h3',\\n    'length_of_text',\\n    'number_of_clickable_button',\\n    'number_of_a',\\n    'number_of_img',\\n    'number_of_div',\\n    'number_of_figure',\\n    'has_footer',\\n    'has_form',\\n    'has_text_area',\\n    'has_iframe',\\n    'has_text_input',\\n    'number_of_meta',\\n    'has_nav',\\n    'has_object',\\n    'has_picture',\\n    'number_of_sources',\\n    'number_of_span',\\n    'number_of_table'\\n]\\ndf = pd.DataFrame(data=data, columns=columns)\\nprint(df.head(5))\\n\""
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#%%writefile fea_ex.py\n",
    "from bs4 import BeautifulSoup\n",
    "import os\n",
    "import fea as fe\n",
    "# import pandas as pd\n",
    "\n",
    "# 1 DEFINE A FUNCTION THAT OPENS A HTML FILE AND RETURNS THE CONTENT\n",
    "file_name = \"mini_dataset/9.html\"\n",
    "\n",
    "\n",
    "def open_file(f_name):\n",
    "    with open(f_name, \"r\") as f:\n",
    "        return f.read()\n",
    "\n",
    "\n",
    "# 2 DEFINE A FUNCTION THAT CREATES A BEATIFULSOUP OBJECT\n",
    "def create_soup(text):\n",
    "    return BeautifulSoup(text, \"html.parser\")\n",
    "\n",
    "\n",
    "# 3 DEFINE A FUNCTION THAT CREATES A VECTOR BY RUNNING ALL FEATURE FUNCTIONS FOR THE SOUP OBJECT\n",
    "def create_vector(soup):\n",
    "    return [\n",
    "        fe.has_title(soup),\n",
    "        fe.has_input(soup),\n",
    "        fe.has_button(soup),\n",
    "        fe.has_image(soup),\n",
    "        fe.has_submit(soup),\n",
    "        fe.has_link(soup),\n",
    "        fe.has_password(soup),\n",
    "        fe.has_email_input(soup),\n",
    "        fe.has_hidden_element(soup),\n",
    "        fe.has_audio(soup),\n",
    "        fe.has_video(soup),\n",
    "        fe.number_of_inputs(soup),\n",
    "        fe.number_of_buttons(soup),\n",
    "        fe.number_of_images(soup),\n",
    "        fe.number_of_option(soup),\n",
    "        fe.number_of_list(soup),\n",
    "        fe.number_of_TH(soup),\n",
    "        fe.number_of_TR(soup),\n",
    "        fe.number_of_href(soup),\n",
    "        fe.number_of_paragraph(soup),\n",
    "        fe.number_of_script(soup),\n",
    "        fe.length_of_title(soup),\n",
    "        fe.has_h1(soup),\n",
    "        fe.has_h2(soup),\n",
    "        fe.has_h3(soup),\n",
    "        fe.length_of_text(soup),\n",
    "        fe.number_of_clickable_button(soup),\n",
    "        fe.number_of_a(soup),\n",
    "        fe.number_of_img(soup),\n",
    "        fe.number_of_div(soup),\n",
    "        fe.number_of_figure(soup),\n",
    "        fe.has_footer(soup),\n",
    "        fe.has_form(soup),\n",
    "        fe.has_text_area(soup),\n",
    "        fe.has_iframe(soup),\n",
    "        fe.has_text_input(soup),\n",
    "        fe.number_of_meta(soup),\n",
    "        fe.has_nav(soup),\n",
    "        fe.has_object(soup),\n",
    "        fe.has_picture(soup),\n",
    "        fe.number_of_sources(soup),\n",
    "        fe.number_of_span(soup),\n",
    "        fe.number_of_table(soup)\n",
    "    ]\n",
    "\n",
    "\n",
    "# 4 RUN STEP 1,2,3 FOR ALL HTML FILES AND CREATE A 2-D ARRAY\n",
    "folder = \"mini_dataset\"\n",
    "\n",
    "\n",
    "def create_2d_list(folder_name):\n",
    "    directory = os.path.join(os.getcwd(), folder_name)\n",
    "    data = []\n",
    "    for file in sorted(os.listdir(directory)):\n",
    "        soup = create_soup(open_file(directory + \"/\" + file))\n",
    "        data.append(create_vector(soup))\n",
    "    return data\n",
    "\n",
    "\"\"\"\n",
    "# 5 CREATE A DATAFRAME BY USING 2-D ARRAY\n",
    "data = create_2d_list(folder)\n",
    "columns = [\n",
    "    'has_title',\n",
    "    'has_input',\n",
    "    'has_button',\n",
    "    'has_image',\n",
    "    'has_submit',\n",
    "    'has_link',\n",
    "    'has_password',\n",
    "    'has_email_input',\n",
    "    'has_hidden_element',\n",
    "    'has_audio',\n",
    "    'has_video',\n",
    "    'number_of_inputs',\n",
    "    'number_of_buttons',\n",
    "    'number_of_images',\n",
    "    'number_of_option',\n",
    "    'number_of_list',\n",
    "    'number_of_th',\n",
    "    'number_of_tr',\n",
    "    'number_of_href',\n",
    "    'number_of_paragraph',\n",
    "    'number_of_script',\n",
    "    'length_of_title',\n",
    "    'has_h1',\n",
    "    'has_h2',\n",
    "    'has_h3',\n",
    "    'length_of_text',\n",
    "    'number_of_clickable_button',\n",
    "    'number_of_a',\n",
    "    'number_of_img',\n",
    "    'number_of_div',\n",
    "    'number_of_figure',\n",
    "    'has_footer',\n",
    "    'has_form',\n",
    "    'has_text_area',\n",
    "    'has_iframe',\n",
    "    'has_text_input',\n",
    "    'number_of_meta',\n",
    "    'has_nav',\n",
    "    'has_object',\n",
    "    'has_picture',\n",
    "    'number_of_sources',\n",
    "    'number_of_span',\n",
    "    'number_of_table'\n",
    "]\n",
    "df = pd.DataFrame(data=data, columns=columns)\n",
    "print(df.head(5))\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a9ea8708",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Writing data_collector\n"
     ]
    }
   ],
   "source": [
    "%%writefile data_collector\n",
    "# data collection\n",
    "import requests as re\n",
    "from urllib3.exceptions import InsecureRequestWarning\n",
    "from urllib3 import disable_warnings\n",
    "\n",
    "# unstructured to structured\n",
    "from bs4 import BeautifulSoup\n",
    "import pandas as pd\n",
    "import fea_ex as fe\n",
    "\n",
    "disable_warnings(InsecureRequestWarning)\n",
    "\n",
    "# Step 1: csv to dataframe\n",
    "URL_file_name = \"tranco_list.csv\"\n",
    "data_frame = pd.read_csv(URL_file_name)\n",
    "\n",
    "# retrieve only \"url\" column and convert it to a list\n",
    "URL_list = data_frame['url'].to_list()\n",
    "\n",
    "# restrict the URL count\n",
    "begin = 35000\n",
    "end = 40000\n",
    "collection_list = URL_list[begin:end]\n",
    "\n",
    "# only for the legitimate\n",
    "# tag = \"http://\"\n",
    "# collection_list = [tag + url for url in collection_list]\n",
    "\n",
    "\n",
    "# function to scrape the content of the URL and convert to a structured form for each\n",
    "def create_structured_data(url_list):\n",
    "    data_list = []\n",
    "    for i in range(0, len(url_list)):\n",
    "        try:\n",
    "            response = re.get(url_list[i], verify=False, timeout=4)\n",
    "            if response.status_code != 200:\n",
    "                print(i, \". HTTP connection was not successful for the URL: \", url_list[i])\n",
    "            else:\n",
    "                soup = BeautifulSoup(response.content, \"html.parser\")\n",
    "                vector = fe.create_vector(soup)\n",
    "                vector.append(str(url_list[i]))\n",
    "                data_list.append(vector)\n",
    "        except re.exceptions.RequestException as e:\n",
    "            print(i, \" --> \", e)\n",
    "            continue\n",
    "    return data_list\n",
    "\n",
    "\n",
    "data = create_structured_data(collection_list)\n",
    "\n",
    "columns = [\n",
    "    'has_title',\n",
    "    'has_input',\n",
    "    'has_button',\n",
    "    'has_image',\n",
    "    'has_submit',\n",
    "    'has_link',\n",
    "    'has_password',\n",
    "    'has_email_input',\n",
    "    'has_hidden_element',\n",
    "    'has_audio',\n",
    "    'has_video',\n",
    "    'number_of_inputs',\n",
    "    'number_of_buttons',\n",
    "    'number_of_images',\n",
    "    'number_of_option',\n",
    "    'number_of_list',\n",
    "    'number_of_th',\n",
    "    'number_of_tr',\n",
    "    'number_of_href',\n",
    "    'number_of_paragraph',\n",
    "    'number_of_script',\n",
    "    'length_of_title',\n",
    "    'has_h1',\n",
    "    'has_h2',\n",
    "    'has_h3',\n",
    "    'length_of_text',\n",
    "    'number_of_clickable_button',\n",
    "    'number_of_a',\n",
    "    'number_of_img',\n",
    "    'number_of_div',\n",
    "    'number_of_figure',\n",
    "    'has_footer',\n",
    "    'has_form',\n",
    "    'has_text_area',\n",
    "    'has_iframe',\n",
    "    'has_text_input',\n",
    "    'number_of_meta',\n",
    "    'has_nav',\n",
    "    'has_object',\n",
    "    'has_picture',\n",
    "    'number_of_sources',\n",
    "    'number_of_span',\n",
    "    'number_of_table',\n",
    "    'URL'\n",
    "]\n",
    "\n",
    "df = pd.DataFrame(data=data, columns=columns)\n",
    "\n",
    "# labelling\n",
    "df['label'] = 0\n",
    "\n",
    "df.to_csv(\"structured_data_phishing.csv\", mode='a', index=False, header=False)  # header should be false after the first run\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "b32218dc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Writing m_l.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile m_l.py\n",
    "# Step 1 import libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn import svm\n",
    "from sklearn import tree\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.gaussian_process import GaussianProcessClassifier\n",
    "from sklearn.gaussian_process.kernels import RBF\n",
    "\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "# Step 2 read the csv files and create pandas dataframes\n",
    "legitimate_df = pd.read_csv(\"structured_data_legitimate.csv\")\n",
    "phishing_df = pd.read_csv(\"structured_data_phishing.csv\")\n",
    "\n",
    "\n",
    "# Step 3 combine legitimate and phishing dataframes, and shuffle\n",
    "df = pd.concat([legitimate_df, phishing_df], axis=0)\n",
    "\n",
    "df = df.sample(frac=1)\n",
    "\n",
    "\n",
    "# Step 4 remove'url' and remove duplicates, then we can create X and Y for the models, Supervised Learning\n",
    "df = df.drop('URL', axis=1)\n",
    "\n",
    "df = df.drop_duplicates()\n",
    "\n",
    "X = df.drop('label', axis=1)\n",
    "Y = df['label']\n",
    "\n",
    "\n",
    "# Step 5 split data to train and test\n",
    "x_train, x_test, y_train, y_test = train_test_split(X, Y, test_size=0.2, random_state=10)\n",
    "\n",
    "\n",
    "# Step 6 create a ML model using sklearn\n",
    "svm_model = svm.LinearSVC()\n",
    "\n",
    "# Random Forest\n",
    "rf_model = RandomForestClassifier(n_estimators=60)\n",
    "\n",
    "# Decision Tree\n",
    "dt_model = tree.DecisionTreeClassifier()\n",
    "\n",
    "# AdaBoost\n",
    "ab_model = AdaBoostClassifier()\n",
    "\n",
    "# Gaussian Naive Bayes\n",
    "nb_model = GaussianNB()\n",
    "\n",
    "# Neural Network\n",
    "nn_model = MLPClassifier(alpha=1)\n",
    "\n",
    "# KNeighborsClassifier\n",
    "kn_model = KNeighborsClassifier()\n",
    "\n",
    "# Gaussian Process\n",
    "#gp_model = GaussianProcessClassifier(1.0 * RBF(1.0))\n",
    "\n",
    "# Step 7 train the model\n",
    "svm_model.fit(x_train, y_train)\n",
    "\n",
    "\n",
    "# Step 8 make some predictions using test data\n",
    "predictions = svm_model.predict(x_test)\n",
    "\n",
    "\n",
    "# Step 9 create a confusion matrix and tn, tp, fn , fp\n",
    "tn, fp, fn, tp = confusion_matrix(y_true=y_test, y_pred=predictions).ravel()\n",
    "\n",
    "\n",
    "# Step 10 calculate accuracy, precision and recall scores\n",
    "accuracy = (tp + tn) / (tp + tn + fp + fn)\n",
    "precision = tp / (tp + fp)\n",
    "recall = tp / (tp + fn)\n",
    "\n",
    "print(\"accuracy --> \", accuracy)\n",
    "print(\"precision --> \", precision)\n",
    "print(\"recall --> \", recall)\n",
    "\n",
    "\n",
    "# K-fold cross validation, and K = 5\n",
    "K = 5\n",
    "total = X.shape[0]\n",
    "index = int(total / K)\n",
    "\n",
    "# 1\n",
    "X_1_test = X.iloc[:index]\n",
    "X_1_train = X.iloc[index:]\n",
    "Y_1_test = Y.iloc[:index]\n",
    "Y_1_train = Y.iloc[index:]\n",
    "\n",
    "# 2\n",
    "X_2_test = X.iloc[index:index*2]\n",
    "X_2_train = X.iloc[np.r_[:index, index*2:]]\n",
    "Y_2_test = Y.iloc[index:index*2]\n",
    "Y_2_train = Y.iloc[np.r_[:index, index*2:]]\n",
    "\n",
    "# 3\n",
    "X_3_test = X.iloc[index*2:index*3]\n",
    "X_3_train = X.iloc[np.r_[:index*2, index*3:]]\n",
    "Y_3_test = Y.iloc[index*2:index*3]\n",
    "Y_3_train = Y.iloc[np.r_[:index*2, index*3:]]\n",
    "\n",
    "# 4\n",
    "X_4_test = X.iloc[index*3:index*4]\n",
    "X_4_train = X.iloc[np.r_[:index*3, index*4:]]\n",
    "Y_4_test = Y.iloc[index*3:index*4]\n",
    "Y_4_train = Y.iloc[np.r_[:index*3, index*4:]]\n",
    "\n",
    "# 5\n",
    "X_5_test = X.iloc[index*4:]\n",
    "X_5_train = X.iloc[:index*4]\n",
    "Y_5_test = Y.iloc[index*4:]\n",
    "Y_5_train = Y.iloc[:index*4]\n",
    "\n",
    "\n",
    "# X and Y train and test lists\n",
    "X_train_list = [X_1_train, X_2_train, X_3_train, X_4_train, X_5_train]\n",
    "X_test_list = [X_1_test, X_2_test, X_3_test, X_4_test, X_5_test]\n",
    "\n",
    "Y_train_list = [Y_1_train, Y_2_train, Y_3_train, Y_4_train, Y_5_train]\n",
    "Y_test_list = [Y_1_test, Y_2_test, Y_3_test, Y_4_test, Y_5_test]\n",
    "\n",
    "\n",
    "def calculate_measures(TN, TP, FN, FP):\n",
    "    model_accuracy = (TP + TN) / (TP + TN + FN + FP)\n",
    "    model_precision = TP / (TP + FP)\n",
    "    model_recall = TP / (TP + FN)\n",
    "    return model_accuracy, model_precision, model_recall\n",
    "\n",
    "\n",
    "rf_accuracy_list, rf_precision_list, rf_recall_list = [], [], []\n",
    "dt_accuracy_list, dt_precision_list, dt_recall_list = [], [], []\n",
    "ab_accuracy_list, ab_precision_list, ab_recall_list = [], [], []\n",
    "svm_accuracy_list, svm_precision_list, svm_recall_list = [], [], []\n",
    "nb_accuracy_list, nb_precision_list, nb_recall_list = [], [], []\n",
    "nn_accuracy_list, nn_precision_list, nn_recall_list = [], [], []\n",
    "kn_accuracy_list, kn_precision_list, kn_recall_list = [], [], []\n",
    "#gp_accuracy_list, gp_precision_list, gp_recall_list = [], [], []\n",
    "\n",
    "\n",
    "for i in range(0, K):\n",
    "    # ----- RANDOM FOREST ----- #\n",
    "    rf_model.fit(X_train_list[i], Y_train_list[i])\n",
    "    rf_predictions = rf_model.predict(X_test_list[i])\n",
    "    tn, fp, fn, tp = confusion_matrix(y_true=Y_test_list[i], y_pred=rf_predictions).ravel()\n",
    "    rf_accuracy, rf_precision, rf_recall = calculate_measures(tn, tp, fn, fp)\n",
    "    rf_accuracy_list.append(rf_accuracy)\n",
    "    rf_precision_list.append(rf_precision)\n",
    "    rf_recall_list.append(rf_recall)\n",
    "\n",
    "    # ----- DECISION TREE ----- #\n",
    "    dt_model.fit(X_train_list[i], Y_train_list[i])\n",
    "    dt_predictions = dt_model.predict(X_test_list[i])\n",
    "    tn, fp, fn, tp = confusion_matrix(y_true=Y_test_list[i], y_pred=dt_predictions).ravel()\n",
    "    dt_accuracy, dt_precision, dt_recall = calculate_measures(tn, tp, fn, fp)\n",
    "    dt_accuracy_list.append(dt_accuracy)\n",
    "    dt_precision_list.append(dt_precision)\n",
    "    dt_recall_list.append(dt_recall)\n",
    "\n",
    "    # ----- SUPPORT VECTOR MACHINE ----- #\n",
    "    svm_model.fit(X_train_list[i], Y_train_list[i])\n",
    "    svm_predictions = svm_model.predict(X_test_list[i])\n",
    "    tn, fp, fn, tp = confusion_matrix(y_true=Y_test_list[i], y_pred=svm_predictions).ravel()\n",
    "    svm_accuracy, svm_precision, svm_recall = calculate_measures(tn, tp, fn, fp)\n",
    "    svm_accuracy_list.append(svm_accuracy)\n",
    "    svm_precision_list.append(svm_precision)\n",
    "    svm_recall_list.append(svm_recall)\n",
    "\n",
    "    # ----- ADABOOST ----- #\n",
    "    ab_model.fit(X_train_list[i], Y_train_list[i])\n",
    "    ab_predictions = ab_model.predict(X_test_list[i])\n",
    "    tn, fp, fn, tp = confusion_matrix(y_true=Y_test_list[i], y_pred=ab_predictions).ravel()\n",
    "    ab_accuracy, ab_precision, ab_recall = calculate_measures(tn, tp, fn, fp)\n",
    "    ab_accuracy_list.append(ab_accuracy)\n",
    "    ab_precision_list.append(ab_precision)\n",
    "    ab_recall_list.append(ab_recall)\n",
    "\n",
    "    # ----- GAUSSIAN NAIVE BAYES ----- #\n",
    "    nb_model.fit(X_train_list[i], Y_train_list[i])\n",
    "    nb_predictions = nb_model.predict(X_test_list[i])\n",
    "    tn, fp, fn, tp = confusion_matrix(y_true=Y_test_list[i], y_pred=nb_predictions).ravel()\n",
    "    nb_accuracy, nb_precision, nb_recall = calculate_measures(tn, tp, fn, fp)\n",
    "    nb_accuracy_list.append(nb_accuracy)\n",
    "    nb_precision_list.append(nb_precision)\n",
    "    nb_recall_list.append(nb_recall)\n",
    "\n",
    "    # ----- NEURAL NETWORK ----- #\n",
    "    nn_model.fit(X_train_list[i], Y_train_list[i])\n",
    "    nn_predictions = nn_model.predict(X_test_list[i])\n",
    "    tn, fp, fn, tp = confusion_matrix(y_true=Y_test_list[i], y_pred=nn_predictions).ravel()\n",
    "    nn_accuracy, nn_precision, nn_recall = calculate_measures(tn, tp, fn, fp)\n",
    "    nn_accuracy_list.append(nn_accuracy)\n",
    "    nn_precision_list.append(nn_precision)\n",
    "    nn_recall_list.append(nn_recall)\n",
    "\n",
    "    # ----- K-NEIGHBOURS CLASSIFIER ----- #\n",
    "    kn_model.fit(X_train_list[i], Y_train_list[i])\n",
    "    kn_predictions = kn_model.predict(X_test_list[i])\n",
    "    tn, fp, fn, tp = confusion_matrix(y_true=Y_test_list[i], y_pred=kn_predictions).ravel()\n",
    "    kn_accuracy, kn_precision, kn_recall = calculate_measures(tn, tp, fn, fp)\n",
    "    kn_accuracy_list.append(kn_accuracy)\n",
    "    kn_precision_list.append(kn_precision)\n",
    "    kn_recall_list.append(kn_recall)\n",
    "\n",
    "    \"\"\"\n",
    "    # ----- GAUSSIAN PROCESS ----- #\n",
    "    gp_model.fit(X_train_list[i], Y_train_list[i])\n",
    "    gp_predictions = gp_model.predict(X_test_list[i])\n",
    "    tn, fp, fn, tp = confusion_matrix(y_true=Y_test_list[i], y_pred=gp_predictions).ravel()\n",
    "    gp_accuracy, gp_precision, gp_recall = calculate_measures(tn, tp, fn, fp)\n",
    "    gp_accuracy_list.append(gp_accuracy)\n",
    "    gp_precision_list.append(gp_precision)\n",
    "    gp_recall_list.append(gp_recall)\n",
    "    \"\"\"\n",
    "\n",
    "RF_accuracy = sum(rf_accuracy_list) / len(rf_accuracy_list)\n",
    "RF_precision = sum(rf_precision_list) / len(rf_precision_list)\n",
    "RF_recall = sum(rf_recall_list) / len(rf_recall_list)\n",
    "\n",
    "print(\"Random Forest accuracy ==> \", RF_accuracy)\n",
    "print(\"Random Forest precision ==> \", RF_precision)\n",
    "print(\"Random Forest recall ==> \", RF_recall)\n",
    "\n",
    "\n",
    "DT_accuracy = sum(dt_accuracy_list) / len(dt_accuracy_list)\n",
    "DT_precision = sum(dt_precision_list) / len(dt_precision_list)\n",
    "DT_recall = sum(dt_recall_list) / len(dt_recall_list)\n",
    "\n",
    "print(\"Decision Tree accuracy ==> \", DT_accuracy)\n",
    "print(\"Decision Tree precision ==> \", DT_precision)\n",
    "print(\"Decision Tree recall ==> \", DT_recall)\n",
    "\n",
    "\n",
    "AB_accuracy = sum(ab_accuracy_list) / len(ab_accuracy_list)\n",
    "AB_precision = sum(ab_precision_list) / len(ab_precision_list)\n",
    "AB_recall = sum(ab_recall_list) / len(ab_recall_list)\n",
    "\n",
    "print(\"AdaBoost accuracy ==> \", AB_accuracy)\n",
    "print(\"AdaBoost precision ==> \", AB_precision)\n",
    "print(\"AdaBoost recall ==> \", AB_recall)\n",
    "\n",
    "\n",
    "SVM_accuracy = sum(svm_accuracy_list) / len(svm_accuracy_list)\n",
    "SVM_precision = sum(svm_precision_list) / len(svm_precision_list)\n",
    "SVM_recall = sum(svm_recall_list) / len(svm_recall_list)\n",
    "\n",
    "print(\"Support Vector Machine accuracy ==> \", SVM_accuracy)\n",
    "print(\"Support Vector Machine precision ==> \", SVM_precision)\n",
    "print(\"Support Vector Machine recall ==> \", SVM_recall)\n",
    "\n",
    "\n",
    "NB_accuracy = sum(nb_accuracy_list) / len(nb_accuracy_list)\n",
    "NB_precision = sum(nb_precision_list) / len(nb_precision_list)\n",
    "NB_recall = sum(nb_recall_list) / len(nb_recall_list)\n",
    "\n",
    "print(\"Gaussian Naive Bayes accuracy ==> \", NB_accuracy)\n",
    "print(\"Gaussian Naive Bayes precision ==> \", NB_precision)\n",
    "print(\"Gaussian Naive Bayes recall ==> \", NB_recall)\n",
    "\n",
    "\n",
    "NN_accuracy = sum(nn_accuracy_list) / len(nn_accuracy_list)\n",
    "NN_precision = sum(nn_precision_list) / len(nn_precision_list)\n",
    "NN_recall = sum(nn_recall_list) / len(nn_recall_list)\n",
    "\n",
    "print(\"Neural Network accuracy ==> \", NN_accuracy)\n",
    "print(\"Neural Network precision ==> \", NN_precision)\n",
    "print(\"Neural Network recall ==> \", NN_recall)\n",
    "\n",
    "\n",
    "KN_accuracy = sum(kn_accuracy_list) / len(kn_accuracy_list)\n",
    "KN_precision = sum(kn_precision_list) / len(kn_precision_list)\n",
    "KN_recall = sum(kn_recall_list) / len(kn_recall_list)\n",
    "\n",
    "print(\"K-Neighbours Classifier accuracy ==> \", KN_accuracy)\n",
    "print(\"K-Neighbours Classifier precision ==> \", KN_precision)\n",
    "print(\"K-Neighbours Classifier recall ==> \", KN_recall)\n",
    "\"\"\"\n",
    "GP_accuracy = sum(gp_accuracy_list) / len(gp_accuracy_list)\n",
    "GP_precision = sum(gp_precision_list) / len(gp_precision_list)\n",
    "GP_recall = sum(gp_recall_list) / len(gp_recall_list)\n",
    "print(\"Gaussian Process accuracy ==> \", GP_accuracy)\n",
    "print(\"Gaussian Process precision ==> \", GP_precision)\n",
    "print(\"Gaussian Process recall ==> \", GP_recall)\n",
    "\"\"\"\n",
    "\n",
    "data = {'accuracy': [NB_accuracy, SVM_accuracy, DT_accuracy, RF_accuracy, AB_accuracy, NN_accuracy, KN_accuracy],\n",
    "        'precision': [NB_precision, SVM_precision, DT_precision, RF_precision, AB_precision, NN_precision, KN_precision],\n",
    "        'recall': [NB_recall, SVM_recall, DT_recall, RF_recall, AB_recall, NN_recall, KN_recall]\n",
    "        }\n",
    "\n",
    "index = ['NB', 'SVM', 'DT', 'RF', 'AB', 'NN', 'KN']\n",
    "\n",
    "df_results = pd.DataFrame(data=data, index=index)\n",
    "\n",
    "\n",
    "# visualize the dataframe\n",
    "ax = df_results.plot.bar(rot=0)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "341f07d4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Writing appp.py\n"
     ]
    }
   ],
   "source": [
    "\n",
    "%%writefile appp.py\n",
    "import streamlit as st\n",
    "import m_l as ml\n",
    "import fea_ex as fe\n",
    "from bs4 import BeautifulSoup\n",
    "import requests as re\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# col1, col2 = st.columns([1, 3])\n",
    "\n",
    "st.title('Phishing Website Detection using Machine Learning')\n",
    "st.write('This ML-based app is developed for educational purposes. Objective of the app is detecting phishing websites only using content data. Not URL!'\n",
    "         ' You can see the details of approach, data set, and feature set if you click on _\"See The Details\"_. ')\n",
    "\n",
    "\n",
    "with st.expander(\"PROJECT DETAILS\"):\n",
    "    st.subheader('Approach')\n",
    "    st.write('I used _supervised learning_ to classify phishing and legitimate websites. '\n",
    "             'I benefit from content-based approach and focus on html of the websites. '\n",
    "             'Also, I used scikit-learn for the ML models.'\n",
    "             )\n",
    "    st.write('For this educational project, '\n",
    "             'I created my own data set and defined features, some from the literature and some based on manual analysis. '\n",
    "             'I used requests library to collect data, BeautifulSoup module to parse and extract features. ')\n",
    "    st.write('The source code and data sets are available in the below Github link:')\n",
    "    st.write('_https://github.com/emre-kocyigit/phishing-website-detection-content-based_')\n",
    "\n",
    "    st.subheader('Data set')\n",
    "    st.write('I used _\"phishtank.org\"_ & _\"tranco-list.eu\"_ as data sources.')\n",
    "    st.write('Totally 26584 websites ==> **_16060_ legitimate** websites | **_10524_ phishing** websites')\n",
    "    st.write('Data set was created in October 2022.')\n",
    "\n",
    "    # ----- FOR THE PIE CHART ----- #\n",
    "    labels = 'phishing', 'legitimate'\n",
    "    phishing_rate = int(ml.phishing_df.shape[0] / (ml.phishing_df.shape[0] + ml.legitimate_df.shape[0]) * 100)\n",
    "    legitimate_rate = 100 - phishing_rate\n",
    "    sizes = [phishing_rate, legitimate_rate]\n",
    "    explode = (0.1, 0)\n",
    "    fig, ax = plt.subplots()\n",
    "    ax.pie(sizes, explode=explode, labels=labels, shadow=True, startangle=90, autopct='%1.1f%%')\n",
    "    ax.axis('equal')\n",
    "    st.pyplot(fig)\n",
    "    # ----- !!!!! ----- #\n",
    "\n",
    "    st.write('Features + URL + Label ==> Dataframe')\n",
    "    st.markdown('label is 1 for phishing, 0 for legitimate')\n",
    "    number = st.slider(\"Select row number to display\", 0, 100)\n",
    "    st.dataframe(ml.legitimate_df.head(number))\n",
    "\n",
    "\n",
    "    @st.cache\n",
    "    def convert_df(df):\n",
    "        # IMPORTANT: Cache the conversion to prevent computation on every rerun\n",
    "        return df.to_csv().encode('utf-8')\n",
    "\n",
    "    csv = convert_df(ml.df)\n",
    "\n",
    "    st.download_button(\n",
    "        label=\"Download data as CSV\",\n",
    "        data=csv,\n",
    "        file_name='phishing_legitimate_structured_data.csv',\n",
    "        mime='text/csv',\n",
    "    )\n",
    "\n",
    "    st.subheader('Features')\n",
    "    st.write('I used only content-based features. I didn\\'t use url-based faetures like length of url etc.'\n",
    "             'Most of the features extracted using find_all() method of BeautifulSoup module after parsing html.')\n",
    "\n",
    "    st.subheader('Results')\n",
    "    st.write('I used 7 different ML classifiers of scikit-learn and tested them implementing k-fold cross validation.'\n",
    "             'Firstly obtained their confusion matrices, then calculated their accuracy, precision and recall scores.'\n",
    "             'Comparison table is below:')\n",
    "    st.table(ml.df_results)\n",
    "    st.write('NB --> Gaussian Naive Bayes')\n",
    "    st.write('SVM --> Support Vector Machine')\n",
    "    st.write('DT --> Decision Tree')\n",
    "    st.write('RF --> Random Forest')\n",
    "    st.write('AB --> AdaBoost')\n",
    "    st.write('NN --> Neural Network')\n",
    "    st.write('KN --> K-Neighbours')\n",
    "\n",
    "with st.expander('EXAMPLE PHISHING URLs:'):\n",
    "    st.write('_https://rtyu38.godaddysites.com/_')\n",
    "    st.write('_https://karafuru.invite-mint.com/_')\n",
    "    st.write('_https://defi-ned.top/h5/#/_')\n",
    "    st.caption('REMEMBER, PHISHING WEB PAGES HAVE SHORT LIFECYCLE! SO, THE EXAMPLES SHOULD BE UPDATED!')\n",
    "\n",
    "choice = st.selectbox(\"Please select your machine learning model\",\n",
    "                 [\n",
    "                     'Gaussian Naive Bayes', 'Support Vector Machine', 'Decision Tree', 'Random Forest',\n",
    "                     'AdaBoost', 'Neural Network', 'K-Neighbours'\n",
    "                 ]\n",
    "                )\n",
    "\n",
    "model = ml.nb_model\n",
    "\n",
    "if choice == 'Gaussian Naive Bayes':\n",
    "    model = ml.nb_model\n",
    "    st.write('GNB model is selected!')\n",
    "elif choice == 'Support Vector Machine':\n",
    "    model = ml.svm_model\n",
    "    st.write('SVM model is selected!')\n",
    "elif choice == 'Decision Tree':\n",
    "    model = ml.dt_model\n",
    "    st.write('DT model is selected!')\n",
    "elif choice == 'Random Forest':\n",
    "    model = ml.rf_model\n",
    "    st.write('RF model is selected!')\n",
    "elif choice == 'AdaBoost':\n",
    "    model = ml.ab_model\n",
    "    st.write('AB model is selected!')\n",
    "elif choice == 'Neural Network':\n",
    "    model = ml.nn_model\n",
    "    st.write('NN model is selected!')\n",
    "else:\n",
    "    model = ml.kn_model\n",
    "    st.write('KN model is selected!')\n",
    "\n",
    "\n",
    "url = st.text_input('Enter the URL')\n",
    "# check the url is valid or not\n",
    "if st.button('Check!'):\n",
    "    try:\n",
    "        response = re.get(url, verify=False, timeout=4)\n",
    "        if response.status_code != 200:\n",
    "            print(\". HTTP connection was not successful for the URL: \", url)\n",
    "        else:\n",
    "            soup = BeautifulSoup(response.content, \"html.parser\")\n",
    "            vector = [fe.create_vector(soup)]  # it should be 2d array, so I added []\n",
    "            result = model.predict(vector)\n",
    "            if result[0] == 0:\n",
    "                st.success(\"This web page seems a legitimate!\")\n",
    "                st.balloons()\n",
    "            else:\n",
    "                st.warning(\"Attention! This web page is a potential PHISHING!\")\n",
    "                st.snow()\n",
    "\n",
    "    except re.exceptions.RequestException as e:\n",
    "        print(\"--> \", e)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "af8af081",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: matplotlib in c:\\users\\mangalore university\\anaconda3\\lib\\site-packages (3.5.2)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in c:\\users\\mangalore university\\anaconda3\\lib\\site-packages (from matplotlib) (4.25.0)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in c:\\users\\mangalore university\\anaconda3\\lib\\site-packages (from matplotlib) (2.8.2)\n",
      "Requirement already satisfied: numpy>=1.17 in c:\\users\\mangalore university\\anaconda3\\lib\\site-packages (from matplotlib) (1.21.5)\n",
      "Requirement already satisfied: cycler>=0.10 in c:\\users\\mangalore university\\anaconda3\\lib\\site-packages (from matplotlib) (0.11.0)\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in c:\\users\\mangalore university\\anaconda3\\lib\\site-packages (from matplotlib) (1.4.2)\n",
      "Requirement already satisfied: pyparsing>=2.2.1 in c:\\users\\mangalore university\\anaconda3\\lib\\site-packages (from matplotlib) (3.0.9)\n",
      "Requirement already satisfied: pillow>=6.2.0 in c:\\users\\mangalore university\\anaconda3\\lib\\site-packages (from matplotlib) (9.2.0)\n",
      "Requirement already satisfied: packaging>=20.0 in c:\\users\\mangalore university\\anaconda3\\lib\\site-packages (from matplotlib) (21.3)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\mangalore university\\anaconda3\\lib\\site-packages (from python-dateutil>=2.7->matplotlib) (1.16.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install matplotlib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70ab6897",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
